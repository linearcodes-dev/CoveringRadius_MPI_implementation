# MPI Parallel Implementation for Computing the Covering Radius of Linear Codes

This work presents a Message Passing Interface (MPI) parallel implementation (provided as a $.cpp$ file) of a known algorithm for computing the covering radius of linear $[n,k]\_q$ ​codes $C$ over finite fields, based on a parity-check matrix.

The algorithm relies on generating linear combinations of the columns of a parity-check matrix $H_{n-k*n}$ and, consequently, the corresponding syndromes of the code $C$. The parallelization strategy is based on partitioning the ordered set $V_n^L$, which represents all non-proportional linear combinations of up to $L$ columns of $H$.

For implementation purposes, ranking and unranking functions are employed to generate ordered subsets of $V_n^L$. An enumeration method for the syndromes of the linear code is also included, as it constitutes a fundamental component of the algorithm.

The MPI parallelization follows a master–worker strategy, where a single master process maintains and tracks the set of generated syndromes, while the worker processes perform the computationally intensive tasks of generating linear combinations. Additionally, vectorization using the SSE4.1 instruction set is incorporated to further accelerate the generation process.

Here we give a Message Passing Interface (MPI) parallel implementation (uploaded .cpp, file) of a known algorithm for computing the Covering Radius of Linear $[n,k]\_q$ Codes $C$ over Finite Fields using a Parity-Check Matrix. The algorithm is based on generation of linear combinations of the columns of a parity-check matrix $H_{n-k*n}$ and therefore the corresponding syndromes of $C$. The parallelization is based on partitioning the ordered set $V_n^L$ that corresponds to all nonproportional linear combinations of up to $L$ columns of $H$. For the purpose, of implementation there is use ranking and unranking functions for generating an ordered subset for $V_n^L$. The enumeration method for the syndromes of the linear code is present, which is an essential part of the algorithm. The Master-Worker strategy is imply for MPI parallelization with. In the presented strategy a single master process tracks the generated syndromes. The workers execute the computational part that consists of generating linear combinations. Vectorization with the SSE4.1 instruction set also take part into the generation.
